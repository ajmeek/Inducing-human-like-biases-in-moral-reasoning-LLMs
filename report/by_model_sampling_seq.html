<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th>timestamp</th>
      <th colspan="3" halign="left">cs_hard_set_acc</th>
      <th colspan="3" halign="left">cs_test_set_acc</th>
      <th colspan="2" halign="left">bs_median</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>max</th>
      <th>mean</th>
      <th>std</th>
      <th>max</th>
      <th>mean</th>
      <th>max</th>
    </tr>
    <tr>
      <th>model_path</th>
      <th>model_size_mln</th>
      <th>sampling_method</th>
      <th>seq_train</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">bert-base-cased</th>
      <th rowspan="3" valign="top">108</th>
      <th rowspan="2" valign="top">AVG</th>
      <th>-</th>
      <td>3</td>
      <td>0.532804</td>
      <td>0.028805</td>
      <td>0.553961</td>
      <td>0.628421</td>
      <td>0.113939</td>
      <td>0.717392</td>
      <td>0.258044</td>
      <td>0.360975</td>
    </tr>
    <tr>
      <th>commonsense then LFB</th>
      <td>2</td>
      <td>0.527713</td>
      <td>0.039191</td>
      <td>0.555425</td>
      <td>0.618290</td>
      <td>0.167287</td>
      <td>0.736579</td>
      <td>0.256573</td>
      <td>0.332623</td>
    </tr>
    <tr>
      <th>LAST</th>
      <th>-</th>
      <td>37</td>
      <td>0.472758</td>
      <td>0.142908</td>
      <td>0.535648</td>
      <td>0.560898</td>
      <td>0.067537</td>
      <td>0.699822</td>
      <td>0.294260</td>
      <td>0.358441</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">bert-large-cased</th>
      <th rowspan="5" valign="top">333</th>
      <th rowspan="2" valign="top">AVG</th>
      <th>-</th>
      <td>13</td>
      <td>0.537238</td>
      <td>0.029038</td>
      <td>0.588272</td>
      <td>0.627205</td>
      <td>0.105306</td>
      <td>0.780203</td>
      <td>0.203178</td>
      <td>0.252768</td>
    </tr>
    <tr>
      <th>commonsense then LFB</th>
      <td>7</td>
      <td>0.530099</td>
      <td>0.038128</td>
      <td>0.595952</td>
      <td>0.594812</td>
      <td>0.104555</td>
      <td>0.777347</td>
      <td>0.275158</td>
      <td>0.296900</td>
    </tr>
    <tr>
      <th>LAST</th>
      <th>-</th>
      <td>26</td>
      <td>0.528556</td>
      <td>0.033206</td>
      <td>0.618500</td>
      <td>0.600235</td>
      <td>0.117562</td>
      <td>0.854267</td>
      <td>0.223800</td>
      <td>0.269990</td>
    </tr>
    <tr>
      <th>MIDDLE</th>
      <th>-</th>
      <td>3</td>
      <td>0.534000</td>
      <td>0.031177</td>
      <td>0.570000</td>
      <td>0.601667</td>
      <td>0.124130</td>
      <td>0.745000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>SENTENCES</th>
      <th>-</th>
      <td>1</td>
      <td>0.516000</td>
      <td>NaN</td>
      <td>0.516000</td>
      <td>0.534000</td>
      <td>NaN</td>
      <td>0.534000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th rowspan="10" valign="top">roberta-large</th>
      <th rowspan="10" valign="top">355</th>
      <th rowspan="3" valign="top">LAST</th>
      <th>commonsense then LFB</th>
      <td>2</td>
      <td>0.609500</td>
      <td>0.159099</td>
      <td>0.722000</td>
      <td>0.673746</td>
      <td>0.251995</td>
      <td>0.851933</td>
      <td>0.065960</td>
      <td>0.065960</td>
    </tr>
    <tr>
      <th>LFB then commonsense</th>
      <td>1</td>
      <td>0.732514</td>
      <td>NaN</td>
      <td>0.732514</td>
      <td>0.905400</td>
      <td>NaN</td>
      <td>0.905400</td>
      <td>0.163941</td>
      <td>0.163941</td>
    </tr>
    <tr>
      <th>-</th>
      <td>8</td>
      <td>0.634905</td>
      <td>0.113713</td>
      <td>0.731689</td>
      <td>0.745972</td>
      <td>0.204351</td>
      <td>0.914400</td>
      <td>0.211418</td>
      <td>0.303664</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">AVG</th>
      <th>commonsense then LFB</th>
      <td>4</td>
      <td>0.500593</td>
      <td>0.002690</td>
      <td>0.504371</td>
      <td>0.497827</td>
      <td>0.004346</td>
      <td>0.500000</td>
      <td>0.275981</td>
      <td>0.336238</td>
    </tr>
    <tr>
      <th>LFB then commonsense</th>
      <td>2</td>
      <td>0.590291</td>
      <td>0.132202</td>
      <td>0.683771</td>
      <td>0.695428</td>
      <td>0.283369</td>
      <td>0.895800</td>
      <td>0.188694</td>
      <td>0.330513</td>
    </tr>
    <tr>
      <th>-</th>
      <td>10</td>
      <td>0.611083</td>
      <td>0.115999</td>
      <td>0.734114</td>
      <td>0.701724</td>
      <td>0.211539</td>
      <td>0.909267</td>
      <td>0.179945</td>
      <td>0.330513</td>
    </tr>
    <tr>
      <th>SENTENCES</th>
      <th>LFB then commonsense</th>
      <td>1</td>
      <td>0.695648</td>
      <td>NaN</td>
      <td>0.695648</td>
      <td>0.898933</td>
      <td>NaN</td>
      <td>0.898933</td>
      <td>0.147456</td>
      <td>0.147456</td>
    </tr>
    <tr>
      <th></th>
      <th>-</th>
      <td>6</td>
      <td>0.574290</td>
      <td>0.115981</td>
      <td>0.741486</td>
      <td>0.634122</td>
      <td>0.208226</td>
      <td>0.905534</td>
      <td>0.237397</td>
      <td>0.290603</td>
    </tr>
    <tr>
      <th>SENTENCES</th>
      <th>-</th>
      <td>3</td>
      <td>0.500389</td>
      <td>0.000674</td>
      <td>0.501167</td>
      <td>0.503400</td>
      <td>0.005889</td>
      <td>0.510200</td>
      <td>0.122376</td>
      <td>0.138236</td>
    </tr>
    <tr>
      <th></th>
      <th>LFB then commonsense</th>
      <td>1</td>
      <td>0.707114</td>
      <td>NaN</td>
      <td>0.707114</td>
      <td>0.917725</td>
      <td>NaN</td>
      <td>0.917725</td>
      <td>0.280265</td>
      <td>0.280265</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">microsoft/deberta-v2-xlarge</th>
      <th rowspan="4" valign="top">884</th>
      <th>SENTENCES</th>
      <th>-</th>
      <td>5</td>
      <td>0.544893</td>
      <td>0.093965</td>
      <td>0.708071</td>
      <td>0.505807</td>
      <td>0.012751</td>
      <td>0.528608</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">AVG</th>
      <th>commonsense then LFB</th>
      <td>1</td>
      <td>0.484500</td>
      <td>NaN</td>
      <td>0.484500</td>
      <td>0.498667</td>
      <td>NaN</td>
      <td>0.498667</td>
      <td>0.172300</td>
      <td>0.172300</td>
    </tr>
    <tr>
      <th>-</th>
      <td>2</td>
      <td>0.498500</td>
      <td>0.000707</td>
      <td>0.499000</td>
      <td>0.499889</td>
      <td>0.002043</td>
      <td>0.501333</td>
      <td>0.226054</td>
      <td>0.281531</td>
    </tr>
    <tr>
      <th>LAST</th>
      <th>-</th>
      <td>4</td>
      <td>0.489295</td>
      <td>0.027606</td>
      <td>0.517241</td>
      <td>0.564354</td>
      <td>0.091434</td>
      <td>0.699732</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>