{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/art/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import webdataset as wds   \n",
    "from typing import Dict, Tuple, Generator\n",
    "import numpy as np\n",
    "import torch\n",
    "from pprint import pp\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _pad_seq_right_to_n(\n",
    "    seq: np.ndarray,\n",
    "    n: int,\n",
    "    pad_value: float = 0.\n",
    "    ) -> np.ndarray:\n",
    "    if n == seq.shape[0]:\n",
    "        return seq\n",
    "    return np.concatenate(\n",
    "        [\n",
    "            seq,\n",
    "            np.ones(\n",
    "                (\n",
    "                    n-seq.shape[0],\n",
    "                    *seq.shape[1:]\n",
    "                )\n",
    "            ) * pad_value,  \n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "\n",
    "class BaseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataloader,\n",
    "        length,\n",
    "        sample_keys\n",
    "        ) -> None:\n",
    "        self.name = 'BaseDataset'\n",
    "        self._length = length\n",
    "        self.dataloader = iter(dataloader)\n",
    "        self.sample_keys = sample_keys\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = next(self.dataloader)\n",
    "            \n",
    "        if self.sample_keys is not None:\n",
    "            sample = {\n",
    "                key: sample[key] \n",
    "                for key in self.sample_keys\n",
    "                if key in sample\n",
    "            }\n",
    "        \n",
    "        return sample\n",
    "\n",
    "\n",
    "class BaseBatcher:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_random_seq: bool = True,\n",
    "        seq_min: int = 10,\n",
    "        seq_max: int = 50,\n",
    "        sample_keys: Tuple[str] = None,\n",
    "        decoding_target: str = None,\n",
    "        seed: int =  None,\n",
    "        bold_dummy_mode: bool = False,\n",
    "        **kwargs\n",
    "        ) -> None:\n",
    "        assert seq_min > 0, \"seq_min must be greater than 0\"\n",
    "        assert seq_min < seq_max, 'seq_min must be less than seq_max'\n",
    "        self.sample_random_seq = sample_random_seq\n",
    "        self.seq_min = seq_min\n",
    "        self.seq_max = seq_max\n",
    "        self.decoding_target = decoding_target\n",
    "        self.sample_keys = sample_keys\n",
    "        self.bold_dummy_mode = bold_dummy_mode\n",
    "        self.seed = seed\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "            torch.manual_seed(self.seed)\n",
    "        \n",
    "    def _make_dataloader(\n",
    "        self,\n",
    "        files,\n",
    "        repeat: bool = True,\n",
    "        n_shuffle_shards: int = 1000,\n",
    "        n_shuffle_samples: int = 1000,\n",
    "        batch_size: int = 1,\n",
    "        num_workers: int = 0\n",
    "        ) -> Generator[Dict[str, torch.tensor], None, None]:\n",
    "        dataset = wds.WebDataset(files)\n",
    "\n",
    "        if n_shuffle_shards is not None:\n",
    "            dataset = dataset.shuffle(n_shuffle_shards)\n",
    "\n",
    "        dataset = dataset.decode(\"pil\").map(self.preprocess_sample)\n",
    "\n",
    "        if repeat:\n",
    "            dataset = dataset.repeat()\n",
    "        \n",
    "        if n_shuffle_samples is not None:\n",
    "            dataset = dataset.shuffle(n_shuffle_samples)\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "\n",
    "    def dataset(\n",
    "        self,\n",
    "        tarfiles: list,\n",
    "        repeat: bool=True,\n",
    "        length: int = 400000,\n",
    "        n_shuffle_shards: int = 1000,\n",
    "        n_shuffle_samples: int = 1000,\n",
    "        num_workers: int = 0\n",
    "        ) -> torch.utils.data.Dataset:\n",
    "        \"\"\"Create Pytorch dataset that can be used for training.\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            tarfiles: list\n",
    "                List of paths to data files (ie., fMRI runs) used for training.\n",
    "            repeat: bool\n",
    "                If True, repeat the dataset indefinitely.\n",
    "            length: int\n",
    "                Maximum number of samples to yield from the dataset.\n",
    "            n_shuffle_shards: int\n",
    "                Buffer for shuffling of tarfiles during training.\n",
    "            n_shuffle_samples: int\n",
    "                Buffer for shuffling of samples during training.\n",
    "            num_workers: int\n",
    "                Number of workers to use for data loading.\n",
    "\n",
    "        Returns:\n",
    "        -----\n",
    "            torch.utils.data.Dataset: Pytorch dataset.\n",
    "        \"\"\"\n",
    "        dataloader = self._make_dataloader(\n",
    "            files=tarfiles,\n",
    "            repeat=repeat,\n",
    "            n_shuffle_shards=n_shuffle_shards,\n",
    "            n_shuffle_samples=n_shuffle_samples,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "        return BaseDataset(\n",
    "            dataloader=dataloader,\n",
    "            length=length,\n",
    "            sample_keys=self.sample_keys\n",
    "        )\n",
    "        \n",
    "    @staticmethod\n",
    "    def _pad_seq_right_to_n(\n",
    "        seq: np.ndarray,\n",
    "        n: int,\n",
    "        pad_value: float = 0\n",
    "        ) -> np.ndarray:\n",
    "        return _pad_seq_right_to_n(\n",
    "            seq=seq,\n",
    "            n=n,\n",
    "            pad_value=pad_value\n",
    "        )\n",
    "    \n",
    "    def _sample_seq_on_and_len(\n",
    "        self,\n",
    "        bold_len: int\n",
    "        ) -> Tuple[int, int]:\n",
    "        \n",
    "        seq_on = 0\n",
    "        if self.sample_random_seq and self.seq_min < bold_len:            \n",
    "            seq_min = min(int(self.seq_min), bold_len)\n",
    "            seq_max = min(int(self.seq_max), bold_len)\n",
    "\n",
    "            if seq_min < seq_max:\n",
    "                seq_len = np.random.randint(\n",
    "                    low=seq_min,\n",
    "                    high=seq_max,\n",
    "                    size=1\n",
    "                )[0]\n",
    "            \n",
    "            else:\n",
    "                seq_len = seq_max\n",
    "            \n",
    "            if seq_len < bold_len:\n",
    "                seq_on = np.random.choice(\n",
    "                    np.arange(\n",
    "                        0,\n",
    "                        bold_len-seq_len,\n",
    "                        seq_len\n",
    "                    ),\n",
    "                    size=1\n",
    "                )[0]\n",
    "        \n",
    "        elif not self.sample_random_seq and self.seq_max < bold_len:\n",
    "            seq_len = self.seq_max\n",
    "\n",
    "        else:\n",
    "            seq_len = bold_len\n",
    "\n",
    "        return seq_on, seq_len\n",
    "\n",
    "    def make_bold_dummy(\n",
    "        self,\n",
    "        bold_shape: Tuple[int, int],\n",
    "        t_r: float, # in seconds\n",
    "        f_s: Tuple[float]=None, # sine frequencies in seconds\n",
    "        ) -> np.ndarray:\n",
    "        f_s = np.array([4, 8, 12]) if f_s is None else np.array(f_s).flatten()\n",
    "        np.random.shuffle(f_s)\n",
    "        f = np.zeros((1, bold_shape[-1]))\n",
    "        for i, f_i in enumerate(f_s):\n",
    "            f[:,i::len(f_s)] = f_i\n",
    "        t_offsets = np.random.choice(\n",
    "            a=np.arange(0,3), # in TRs\n",
    "            size=bold_shape[1],\n",
    "            replace=True\n",
    "        )\n",
    "        t = np.concatenate(\n",
    "            [\n",
    "                np.arange(\n",
    "                    t_offsets[i],\n",
    "                    bold_shape[0]+t_offsets[i]\n",
    "                ).reshape(-1,1)\n",
    "                for i in range(bold_shape[1])\n",
    "            ],\n",
    "            axis=-1\n",
    "        ) * t_r\n",
    "        return np.sin((1. / f) * t)\n",
    "\n",
    "    def preprocess_sample(\n",
    "        self,\n",
    "        sample\n",
    "        ) -> Dict[str, torch.Tensor]:\n",
    "        out = dict(__key__=sample[\"__key__\"])\n",
    "        t_r = sample[\"t_r.pyd\"]\n",
    "\n",
    "        label = None\n",
    "        f_s = None\n",
    "        if self.bold_dummy_mode and self.decoding_target is not None:\n",
    "            label = np.random.choice([0, 1])\n",
    "            f_s = np.array([1, 2, 4]) if label == 0 else np.array([6, 8, 10])                \n",
    "\n",
    "        for key, value in sample.items():\n",
    "            if key == \"bold.pyd\":\n",
    "\n",
    "                bold = np.array(value).astype(float)\n",
    "                \n",
    "                if self.bold_dummy_mode:\n",
    "                    bold = self.make_bold_dummy(\n",
    "                        bold_shape=bold.shape,\n",
    "                        t_r=t_r,\n",
    "                        f_s=f_s\n",
    "                    )\n",
    "\n",
    "                seq_on, seq_len = self._sample_seq_on_and_len(bold_len=len(bold))\n",
    "                bold = bold[seq_on:seq_on+seq_len]\n",
    "                t_rs = np.arange(seq_len) * t_r\n",
    "                attention_mask = np.ones(seq_len)\n",
    "                bold = self._pad_seq_right_to_n(\n",
    "                    seq=bold,\n",
    "                    n=self.seq_max,\n",
    "                    pad_value=0\n",
    "                )\n",
    "                t_rs = self._pad_seq_right_to_n(\n",
    "                    seq=t_rs,\n",
    "                    n=self.seq_max,\n",
    "                    pad_value=0\n",
    "                )\n",
    "                attention_mask = self._pad_seq_right_to_n(\n",
    "                    seq=attention_mask,\n",
    "                    n=self.seq_max,\n",
    "                    pad_value=0\n",
    "                )\n",
    "                out[\"inputs\"] = torch.from_numpy(bold).to(torch.float)\n",
    "                out['t_rs'] = torch.from_numpy(t_rs).to(torch.float)\n",
    "                out[\"attention_mask\"] = torch.from_numpy(attention_mask).to(torch.long)\n",
    "                out['seq_on'] = seq_on\n",
    "                out['seq_len'] = seq_len\n",
    "\n",
    "            elif key in {\n",
    "                f\"{self.decoding_target}.pyd\",\n",
    "                self.decoding_target\n",
    "                }:\n",
    "                out[\"labels\"] = value\n",
    "\n",
    "            else:\n",
    "                out[key] = value\n",
    "        \n",
    "        if self.sample_keys is not None:\n",
    "            out = {\n",
    "                key: out[key] \n",
    "                for key in self.sample_keys\n",
    "                if key in out\n",
    "            }\n",
    "\n",
    "        if label is not None:\n",
    "            out['labels'] = label\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#url = \"https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar\"\n",
    "#dataset = BaseBatcher(seq_max=300, sample_random_seq=False).dataset(tarfiles=[url])\n",
    "\n",
    "dataset = BaseBatcher(seq_max=300, sample_random_seq=False).dataset(tarfiles=[str(f) for f in Path('.').glob('*.tar')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loaded \u001b[39m=\u001b[39m [e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m dataset]\n",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loaded \u001b[39m=\u001b[39m [e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m dataset]\n",
      "Cell \u001b[0;32mIn[10], line 39\u001b[0m, in \u001b[0;36mBaseDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m---> 39\u001b[0m     sample \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader)\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_keys \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         sample \u001b[39m=\u001b[39m {\n\u001b[1;32m     43\u001b[0m             key: sample[key] \n\u001b[1;32m     44\u001b[0m             \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_keys\n\u001b[1;32m     45\u001b[0m             \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m sample\n\u001b[1;32m     46\u001b[0m         }\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:34\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     33\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m         data\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_iter))\n\u001b[1;32m     35\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mended \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/webdataset/pipeline.py:64\u001b[0m, in \u001b[0;36mDataPipeline.iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create an iterator through the entire dataset, using the given number of repetitions.\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepetitions):\n\u001b[0;32m---> 64\u001b[0m     \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator1():\n\u001b[1;32m     65\u001b[0m         \u001b[39myield\u001b[39;00m sample\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/webdataset/filters.py:208\u001b[0m, in \u001b[0;36m_shuffle\u001b[0;34m(data, bufsize, initial, rng, handler)\u001b[0m\n\u001b[1;32m    206\u001b[0m initial \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(initial, bufsize)\n\u001b[1;32m    207\u001b[0m buf \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 208\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m data:\n\u001b[1;32m    209\u001b[0m     buf\u001b[39m.\u001b[39mappend(sample)\n\u001b[1;32m    210\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buf) \u001b[39m<\u001b[39m bufsize:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/webdataset/filters.py:297\u001b[0m, in \u001b[0;36m_map\u001b[0;34m(data, f, handler)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_map\u001b[39m(data, f, handler\u001b[39m=\u001b[39mreraise_exception):\n\u001b[1;32m    296\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Map samples.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m     \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m data:\n\u001b[1;32m    298\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m             result \u001b[39m=\u001b[39m f(sample)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/webdataset/filters.py:297\u001b[0m, in \u001b[0;36m_map\u001b[0;34m(data, f, handler)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_map\u001b[39m(data, f, handler\u001b[39m=\u001b[39mreraise_exception):\n\u001b[1;32m    296\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Map samples.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m     \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m data:\n\u001b[1;32m    298\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m             result \u001b[39m=\u001b[39m f(sample)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/webdataset/filters.py:208\u001b[0m, in \u001b[0;36m_shuffle\u001b[0;34m(data, bufsize, initial, rng, handler)\u001b[0m\n\u001b[1;32m    206\u001b[0m initial \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(initial, bufsize)\n\u001b[1;32m    207\u001b[0m buf \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 208\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m data:\n\u001b[1;32m    209\u001b[0m     buf\u001b[39m.\u001b[39mappend(sample)\n\u001b[1;32m    210\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buf) \u001b[39m<\u001b[39m bufsize:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/webdataset/tariterators.py:218\u001b[0m, in \u001b[0;36mgroup_by_keys\u001b[0;34m(data, keys, lcase, suffixes, handler)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Group tarfile contents by keys and yield samples.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \n\u001b[1;32m    204\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39m    iterator over samples.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    217\u001b[0m current_sample \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m \u001b[39mfor\u001b[39;00m filesample \u001b[39min\u001b[39;00m data:\n\u001b[1;32m    219\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(filesample, \u001b[39mdict\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/webdataset/tariterators.py:176\u001b[0m, in \u001b[0;36mtar_file_expander\u001b[0;34m(data, handler, select_files, rename_files)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(source, \u001b[39mdict\u001b[39m)\n\u001b[1;32m    175\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m source\n\u001b[0;32m--> 176\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m tar_file_iterator(\n\u001b[1;32m    177\u001b[0m     source[\u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    178\u001b[0m     handler\u001b[39m=\u001b[39mhandler,\n\u001b[1;32m    179\u001b[0m     select_files\u001b[39m=\u001b[39mselect_files,\n\u001b[1;32m    180\u001b[0m     rename_files\u001b[39m=\u001b[39mrename_files,\n\u001b[1;32m    181\u001b[0m ):\n\u001b[1;32m    182\u001b[0m     \u001b[39massert\u001b[39;00m (\n\u001b[1;32m    183\u001b[0m         \u001b[39misinstance\u001b[39m(sample, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m sample \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfname\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m sample\n\u001b[1;32m    184\u001b[0m     )\n\u001b[1;32m    185\u001b[0m     sample[\u001b[39m\"\u001b[39m\u001b[39m__url__\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m url\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/webdataset/tariterators.py:141\u001b[0m, in \u001b[0;36mtar_file_iterator\u001b[0;34m(fileobj, skip_meta, handler, select_files, rename_files)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m select_files \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m select_files(fname):\n\u001b[1;32m    140\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m data \u001b[39m=\u001b[39m stream\u001b[39m.\u001b[39;49mextractfile(tarinfo)\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    142\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(fname\u001b[39m=\u001b[39mfname, data\u001b[39m=\u001b[39mdata)\n\u001b[1;32m    143\u001b[0m \u001b[39myield\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.10/tarfile.py:685\u001b[0m, in \u001b[0;36m_FileInFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    684\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfileobj\u001b[39m.\u001b[39mseek(offset \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition \u001b[39m-\u001b[39m start))\n\u001b[0;32m--> 685\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfileobj\u001b[39m.\u001b[39;49mread(length)\n\u001b[1;32m    686\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(b) \u001b[39m!=\u001b[39m length:\n\u001b[1;32m    687\u001b[0m         \u001b[39mraise\u001b[39;00m ReadError(\u001b[39m\"\u001b[39m\u001b[39munexpected end of data\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/tarfile.py:522\u001b[0m, in \u001b[0;36m_Stream.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the next size number of bytes from the stream.\"\"\"\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[39massert\u001b[39;00m size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read(size)\n\u001b[1;32m    523\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(buf)\n\u001b[1;32m    524\u001b[0m \u001b[39mreturn\u001b[39;00m buf\n",
      "File \u001b[0;32m/usr/lib/python3.10/tarfile.py:530\u001b[0m, in \u001b[0;36m_Stream._read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return size bytes from the stream.\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomptype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtar\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__read(size)\n\u001b[1;32m    532\u001b[0m c \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdbuf)\n\u001b[1;32m    533\u001b[0m t \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdbuf]\n",
      "File \u001b[0;32m/usr/lib/python3.10/tarfile.py:560\u001b[0m, in \u001b[0;36m_Stream.__read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    558\u001b[0m t \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf]\n\u001b[1;32m    559\u001b[0m \u001b[39mwhile\u001b[39;00m c \u001b[39m<\u001b[39m size:\n\u001b[0;32m--> 560\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfileobj\u001b[39m.\u001b[39;49mread(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbufsize)\n\u001b[1;32m    561\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m buf:\n\u001b[1;32m    562\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loaded = [e for e in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({166: 25, 110: 13, 136: 12})\n",
      "Counter({'ds-ds000212_sub-28_task-dis_run-3': 1,\n",
      "         'ds-ds000212_sub-47_task-tom_run-1': 1,\n",
      "         'ds-ds000212_sub-22_task-dis_run-5': 1,\n",
      "         'ds-ds000212_sub-29_task-fb_run-3': 1,\n",
      "         'ds-ds000212_sub-27_task-fb_run-4': 1,\n",
      "         'ds-ds000212_sub-41_task-dis_run-3': 1,\n",
      "         'ds-ds000212_sub-38_task-dis_run-5': 1,\n",
      "         'ds-ds000212_sub-45_task-dis_run-6': 1,\n",
      "         'ds-ds000212_sub-20_task-dis_run-1': 1,\n",
      "         'ds-ds000212_sub-06_task-fb_run-4': 1,\n",
      "         'ds-ds000212_sub-08_task-dis_run-4': 1,\n",
      "         'ds-ds000212_sub-04_task-fb_run-4': 1,\n",
      "         'ds-ds000212_sub-41_task-tomloc_run-1': 1,\n",
      "         'ds-ds000212_sub-27_task-fb_run-1': 1,\n",
      "         'ds-ds000212_sub-19_task-fb_run-1': 1,\n",
      "         'ds-ds000212_sub-30_task-dis_run-3': 1,\n",
      "         'ds-ds000212_sub-24_task-dis_run-2': 1,\n",
      "         'ds-ds000212_sub-16_task-dis_run-6': 1,\n",
      "         'ds-ds000212_sub-05_task-dis_run-1': 1,\n",
      "         'ds-ds000212_sub-14_task-fb_run-1': 1,\n",
      "         'ds-ds000212_sub-14_task-dis_run-6': 1,\n",
      "         'ds-ds000212_sub-46_task-tom_run-1': 1,\n",
      "         'ds-ds000212_sub-30_task-fb_run-1': 1,\n",
      "         'ds-ds000212_sub-38_task-tom_run-2': 1,\n",
      "         'ds-ds000212_sub-32_task-dis_run-5': 1,\n",
      "         'ds-ds000212_sub-17_task-dis_run-6': 1,\n",
      "         'ds-ds000212_sub-28_task-dis_run-5': 1,\n",
      "         'ds-ds000212_sub-41_task-tomloc_run-2': 1,\n",
      "         'ds-ds000212_sub-09_task-dis_run-2': 1,\n",
      "         'ds-ds000212_sub-31_task-fb_run-1': 1,\n",
      "         'ds-ds000212_sub-20_task-fb_run-3': 1,\n",
      "         'ds-ds000212_sub-16_task-fb_run-3': 1,\n",
      "         'ds-ds000212_sub-03_task-dis_run-4': 1,\n",
      "         'ds-ds000212_sub-24_task-dis_run-5': 1,\n",
      "         'ds-ds000212_sub-33_task-dis_run-4': 1,\n",
      "         'ds-ds000212_sub-28_task-fb_run-2': 1,\n",
      "         'ds-ds000212_sub-41_task-dis_run-5': 1,\n",
      "         'ds-ds000212_sub-34_task-fb_run-1': 1,\n",
      "         'ds-ds000212_sub-13_task-fb_run-2': 1,\n",
      "         'ds-ds000212_sub-18_task-fb_run-4': 1,\n",
      "         'ds-ds000212_sub-06_task-fb_run-3': 1,\n",
      "         'ds-ds000212_sub-46_task-dis_run-3': 1,\n",
      "         'ds-ds000212_sub-12_task-dis_run-6': 1,\n",
      "         'ds-ds000212_sub-34_task-dis_run-3': 1,\n",
      "         'ds-ds000212_sub-41_task-dis_run-6': 1,\n",
      "         'ds-ds000212_sub-31_task-fb_run-2': 1,\n",
      "         'ds-ds000212_sub-46_task-tom_run-2': 1,\n",
      "         'ds-ds000212_sub-29_task-dis_run-1': 1,\n",
      "         'ds-ds000212_sub-42_task-tom_run-1': 1,\n",
      "         'ds-ds000212_sub-23_task-fb_run-4': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "pp(Counter(l['seq_len'].item() for l in loaded))\n",
    "pp(Counter(l['__key__'][0] for l in loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n",
      "['__key__', ['ds-ds000212_sub-03_task-dis_run-1']]\n",
      "['__url__',\n",
      " ['https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar']]\n",
      "inputs torch.Size([1, 300, 1024]) torch.float32\n",
      "t_rs torch.Size([1, 300]) torch.float32\n",
      "attention_mask torch.Size([1, 300]) torch.int64\n",
      "seq_on tensor([0])\n",
      "seq_len tensor([166])\n",
      "t_r.pyd tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "for l in loaded:\n",
    "    for f in l:\n",
    "        if isinstance(l[f], torch.Tensor):\n",
    "            if len(l[f].shape) == 1:\n",
    "                print(f, l[f])\n",
    "            else:\n",
    "                print(f, l[f].shape, l[f].dtype)\n",
    "        else:\n",
    "            pp([f, l[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Inducing-human-like-biases-in-moral-reason-eYvEhHxD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
