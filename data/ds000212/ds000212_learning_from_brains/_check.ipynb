{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/art/.local/share/virtualenvs/Inducing-human-like-biases-in-moral-reason-eYvEhHxD/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import webdataset as wds   \n",
    "from typing import Dict, Tuple, Generator\n",
    "import numpy as np\n",
    "import torch\n",
    "from pprint import pp\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataloader,\n",
    "        length,\n",
    "        sample_keys\n",
    "        ) -> None:\n",
    "        self.name = 'BaseDataset'\n",
    "        self._length = length\n",
    "        self.dataloader = iter(dataloader)\n",
    "        self.sample_keys = sample_keys\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = next(self.dataloader)\n",
    "            \n",
    "        if self.sample_keys is not None:\n",
    "            sample = {\n",
    "                key: sample[key] \n",
    "                for key in self.sample_keys\n",
    "                if key in sample\n",
    "            }\n",
    "        \n",
    "        return sample\n",
    "\n",
    "\n",
    "class BaseBatcher:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_random_seq: bool = True,\n",
    "        seq_min: int = 10,\n",
    "        seq_max: int = 50,\n",
    "        sample_keys: Tuple[str] = None,\n",
    "        decoding_target: str = None,\n",
    "        seed: int =  None,\n",
    "        **kwargs\n",
    "        ) -> None:\n",
    "        assert seq_min > 0, \"seq_min must be greater than 0\"\n",
    "        assert seq_min < seq_max, 'seq_min must be less than seq_max'\n",
    "        self.sample_random_seq = sample_random_seq\n",
    "        self.seq_min = seq_min\n",
    "        self.seq_max = seq_max\n",
    "        self.decoding_target = decoding_target\n",
    "        self.sample_keys = sample_keys\n",
    "        self.seed = seed\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "            torch.manual_seed(self.seed)\n",
    "        \n",
    "    def _make_dataloader(\n",
    "        self,\n",
    "        files,\n",
    "        repeat: bool = True,\n",
    "        n_shuffle_shards: int = 1000,\n",
    "        n_shuffle_samples: int = 1000,\n",
    "        batch_size: int = 1,\n",
    "        num_workers: int = 0\n",
    "        ) -> Generator[Dict[str, torch.tensor], None, None]:\n",
    "        dataset = wds.WebDataset(files)\n",
    "\n",
    "        if n_shuffle_shards is not None:\n",
    "            dataset = dataset.shuffle(n_shuffle_shards)\n",
    "\n",
    "        dataset = dataset.decode(\"pil\").compose(self.get_samples) # .map(self.preprocess_sample)\n",
    "\n",
    "        if repeat:\n",
    "            dataset = dataset.repeat()\n",
    "        \n",
    "        if n_shuffle_samples is not None:\n",
    "            dataset = dataset.shuffle(n_shuffle_samples)\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "\n",
    "    def dataset(\n",
    "        self,\n",
    "        tarfiles: list,\n",
    "        repeat: bool=True,\n",
    "        length: int = 400000,\n",
    "        n_shuffle_shards: int = 1000,\n",
    "        n_shuffle_samples: int = 1000,\n",
    "        num_workers: int = 0\n",
    "        ) -> torch.utils.data.Dataset:\n",
    "        \"\"\"Create Pytorch dataset that can be used for training.\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            tarfiles: list\n",
    "                List of paths to data files (ie., fMRI runs) used for training.\n",
    "            repeat: bool\n",
    "                If True, repeat the dataset indefinitely.\n",
    "            length: int\n",
    "                Maximum number of samples to yield from the dataset.\n",
    "            n_shuffle_shards: int\n",
    "                Buffer for shuffling of tarfiles during training.\n",
    "            n_shuffle_samples: int\n",
    "                Buffer for shuffling of samples during training.\n",
    "            num_workers: int\n",
    "                Number of workers to use for data loading.\n",
    "\n",
    "        Returns:\n",
    "        -----\n",
    "            torch.utils.data.Dataset: Pytorch dataset.\n",
    "        \"\"\"\n",
    "        dataloader = self._make_dataloader(\n",
    "            files=tarfiles,\n",
    "            repeat=repeat,\n",
    "            n_shuffle_shards=n_shuffle_shards,\n",
    "            n_shuffle_samples=n_shuffle_samples,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "        return BaseDataset(\n",
    "            dataloader=dataloader,\n",
    "            length=length,\n",
    "            sample_keys=self.sample_keys\n",
    "        )\n",
    "\n",
    "    def get_samples(self, src):\n",
    "        for sample in src:\n",
    "            #key = sample['__key__']\n",
    "            out = dict()\n",
    "            bold = None\n",
    "            for key, value in sample.items():\n",
    "                #print(f\" {key=} {value=}\")\n",
    "                if key == \"bold.pyd\":\n",
    "                    bold = np.array(value).astype(float)\n",
    "                else:\n",
    "                    out[key] = value\n",
    "\n",
    "            if bold is not None:\n",
    "                parts = [(0, bold.shape[0]//2 - 1), (bold.shape[0]//2, bold.shape[0])]\n",
    "                for start, end in parts:\n",
    "                    #out['__key__'] = f\"{key} {start}-{end}\"\n",
    "                    out['start'] = start\n",
    "                    out['end'] = end\n",
    "                    out[\"inputs\"] = torch.from_numpy(bold[start:end+1]).to(torch.float)\n",
    "                    yield out.copy()\n",
    "\n",
    "    #def preprocess_sample(\n",
    "    #    self,\n",
    "    #    sample\n",
    "    #    ) -> Dict[str, torch.Tensor]:\n",
    "    #    out = dict(__key__=sample[\"__key__\"])\n",
    "    #    t_r = sample[\"t_r.pyd\"]\n",
    "\n",
    "    #    label = None\n",
    "    #    f_s = None\n",
    "    #    if self.bold_dummy_mode and self.decoding_target is not None:\n",
    "    #        label = np.random.choice([0, 1])\n",
    "    #        f_s = np.array([1, 2, 4]) if label == 0 else np.array([6, 8, 10])                \n",
    "\n",
    "    #    for key, value in sample.items():\n",
    "    #        if key == \"bold.pyd\":\n",
    "\n",
    "    #            bold = np.array(value).astype(float)\n",
    "    #            \n",
    "    #            if self.bold_dummy_mode:\n",
    "    #                bold = self.make_bold_dummy(\n",
    "    #                    bold_shape=bold.shape,\n",
    "    #                    t_r=t_r,\n",
    "    #                    f_s=f_s\n",
    "    #                )\n",
    "\n",
    "    #            seq_on, seq_len = self._sample_seq_on_and_len(bold_len=len(bold))\n",
    "    #            bold = bold[seq_on:seq_on+seq_len]\n",
    "    #            t_rs = np.arange(seq_len) * t_r\n",
    "    #            attention_mask = np.ones(seq_len)\n",
    "    #            bold = self._pad_seq_right_to_n(\n",
    "    #                seq=bold,\n",
    "    #                n=self.seq_max,\n",
    "    #                pad_value=0\n",
    "    #            )\n",
    "    #            t_rs = self._pad_seq_right_to_n(\n",
    "    #                seq=t_rs,\n",
    "    #                n=self.seq_max,\n",
    "    #                pad_value=0\n",
    "    #            )\n",
    "    #            attention_mask = self._pad_seq_right_to_n(\n",
    "    #                seq=attention_mask,\n",
    "    #                n=self.seq_max,\n",
    "    #                pad_value=0\n",
    "    #            )\n",
    "    #            out[\"inputs\"] = torch.from_numpy(bold).to(torch.float)\n",
    "    #            out['t_rs'] = torch.from_numpy(t_rs).to(torch.float)\n",
    "    #            out[\"attention_mask\"] = torch.from_numpy(attention_mask).to(torch.long)\n",
    "    #            out['seq_on'] = seq_on\n",
    "    #            out['seq_len'] = seq_len\n",
    "\n",
    "    #        elif key in {\n",
    "    #            f\"{self.decoding_target}.pyd\",\n",
    "    #            self.decoding_target\n",
    "    #            }:\n",
    "    #            out[\"labels\"] = value\n",
    "\n",
    "    #        else:\n",
    "    #            out[key] = value\n",
    "    #    \n",
    "    #    if self.sample_keys is not None:\n",
    "    #        out = {\n",
    "    #            key: out[key] \n",
    "    #            for key in self.sample_keys\n",
    "    #            if key in out\n",
    "    #        }\n",
    "\n",
    "    #    if label is not None:\n",
    "    #        out['labels'] = label\n",
    "    #    \n",
    "    #    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#url = \"https://github.com/athms/learning-from-brains/raw/b061ef97680365a074671e0c95581af426773f9e/data/upstream/ds000212/ds-ds000212_sub-[03-47]_task-dis_run-[1-6].tar\"\n",
    "#dataset = BaseBatcher(seq_max=300, sample_random_seq=False).dataset(tarfiles=[url])\n",
    "\n",
    "dataset = BaseBatcher(seq_max=300, sample_random_seq=False).dataset(tarfiles=[str(f) for f in Path('.').glob('*.tar')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = [dataset[i] for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "['__key__', ['ds-ds000212_sub-34_task-dis_run-6']]\n",
      "['__url__', ['ds-ds000212_sub-34_task-dis_run-6.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-04_task-fb_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-04_task-fb_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([67])\n",
      "inputs torch.Size([1, 68, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-13_task-dis_run-6']]\n",
      "['__url__', ['ds-ds000212_sub-13_task-dis_run-6.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-46_task-dis_run-2']]\n",
      "['__url__', ['ds-ds000212_sub-46_task-dis_run-2.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-32_task-dis_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-32_task-dis_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-41_task-dis_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-41_task-dis_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-18_task-fb_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-18_task-fb_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([55])\n",
      "end tensor([110])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-38_task-dis_run-5']]\n",
      "['__url__', ['ds-ds000212_sub-38_task-dis_run-5.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-20_task-dis_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-20_task-dis_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-10_task-dis_run-4']]\n",
      "['__url__', ['ds-ds000212_sub-10_task-dis_run-4.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-39_task-dis_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-39_task-dis_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-05_task-fb_run-2']]\n",
      "['__url__', ['ds-ds000212_sub-05_task-fb_run-2.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([68])\n",
      "end tensor([136])\n",
      "inputs torch.Size([1, 68, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-04_task-fb_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-04_task-fb_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([67])\n",
      "inputs torch.Size([1, 68, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-17_task-dis_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-17_task-dis_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-28_task-fb_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-28_task-fb_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([54])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-09_task-dis_run-4']]\n",
      "['__url__', ['ds-ds000212_sub-09_task-dis_run-4.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-27_task-fb_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-27_task-fb_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([54])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-14_task-dis_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-14_task-dis_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-20_task-dis_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-20_task-dis_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-38_task-dis_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-38_task-dis_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-39_task-dis_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-39_task-dis_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-15_task-dis_run-4']]\n",
      "['__url__', ['ds-ds000212_sub-15_task-dis_run-4.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-23_task-fb_run-2']]\n",
      "['__url__', ['ds-ds000212_sub-23_task-fb_run-2.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([55])\n",
      "end tensor([110])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-05_task-dis_run-5']]\n",
      "['__url__', ['ds-ds000212_sub-05_task-dis_run-5.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-45_task-tomloc_run-2']]\n",
      "['__url__', ['ds-ds000212_sub-45_task-tomloc_run-2.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([67])\n",
      "inputs torch.Size([1, 68, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-17_task-fb_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-17_task-fb_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([55])\n",
      "end tensor([110])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-27_task-fb_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-27_task-fb_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([55])\n",
      "end tensor([110])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-28_task-dis_run-5']]\n",
      "['__url__', ['ds-ds000212_sub-28_task-dis_run-5.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-18_task-fb_run-4']]\n",
      "['__url__', ['ds-ds000212_sub-18_task-fb_run-4.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([55])\n",
      "end tensor([110])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-17_task-dis_run-2']]\n",
      "['__url__', ['ds-ds000212_sub-17_task-dis_run-2.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([33])\n",
      "end tensor([67])\n",
      "inputs torch.Size([1, 34, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-19_task-fb_run-2']]\n",
      "['__url__', ['ds-ds000212_sub-19_task-fb_run-2.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([54])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-44_task-dis_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-44_task-dis_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-16_task-fb_run-4']]\n",
      "['__url__', ['ds-ds000212_sub-16_task-fb_run-4.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([55])\n",
      "end tensor([110])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-45_task-tomloc_run-2']]\n",
      "['__url__', ['ds-ds000212_sub-45_task-tomloc_run-2.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([68])\n",
      "end tensor([136])\n",
      "inputs torch.Size([1, 68, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-28_task-dis_run-6']]\n",
      "['__url__', ['ds-ds000212_sub-28_task-dis_run-6.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-28_task-fb_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-28_task-fb_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([55])\n",
      "end tensor([110])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-17_task-fb_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-17_task-fb_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([54])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-29_task-dis_run-5']]\n",
      "['__url__', ['ds-ds000212_sub-29_task-dis_run-5.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-38_task-dis_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-38_task-dis_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-13_task-fb_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-13_task-fb_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([68])\n",
      "end tensor([136])\n",
      "inputs torch.Size([1, 68, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-29_task-dis_run-5']]\n",
      "['__url__', ['ds-ds000212_sub-29_task-dis_run-5.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-19_task-dis_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-19_task-dis_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-24_task-fb_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-24_task-fb_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([54])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-41_task-dis_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-41_task-dis_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-44_task-tom_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-44_task-tom_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([67])\n",
      "inputs torch.Size([1, 68, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-15_task-dis_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-15_task-dis_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-05_task-dis_run-5']]\n",
      "['__url__', ['ds-ds000212_sub-05_task-dis_run-5.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-09_task-dis_run-3']]\n",
      "['__url__', ['ds-ds000212_sub-09_task-dis_run-3.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([83])\n",
      "end tensor([166])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-19_task-fb_run-1']]\n",
      "['__url__', ['ds-ds000212_sub-19_task-fb_run-1.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([54])\n",
      "inputs torch.Size([1, 55, 1024]) torch.float32\n",
      "---\n",
      "['__key__', ['ds-ds000212_sub-24_task-dis_run-2']]\n",
      "['__url__', ['ds-ds000212_sub-24_task-dis_run-2.tar']]\n",
      "t_r.pyd tensor([2.])\n",
      "start tensor([0])\n",
      "end tensor([82])\n",
      "inputs torch.Size([1, 83, 1024]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for l in loaded:\n",
    "    print('---')\n",
    "    for f in l:\n",
    "        if isinstance(l[f], torch.Tensor):\n",
    "            if len(l[f].shape) == 1:\n",
    "                print(f, l[f])\n",
    "            else:\n",
    "                print(f, l[f].shape, l[f].dtype)\n",
    "        else:\n",
    "            pp([f, l[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Inducing-human-like-biases-in-moral-reason-eYvEhHxD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
